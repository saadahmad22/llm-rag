Put your Llama GGUF model in here as [specified by the library](https://github.com/ggml-org/llama.cpp#:~:text=llama.cpp%20requires,%239669).
Download model: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/blob/main/Llama-3.2-3B-Instruct-Q6_K.gguf

Then, update the [configuration file](../src/config)
